{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyarrow.parquet as pq\n",
    "from textDataset import TranslationDataset, get_and_split_dataset\n",
    "from model import Transformer, Translator\n",
    "from utils import load_tokenizer, load_data, build_tokenizer, get_config\n",
    "from train import train\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config.json'\n",
    "h = get_config(config_path)\n",
    "ckpt_path = 'ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    N=h.N, \n",
    "    d_model=h.d_model, \n",
    "    num_heads=h.num_heads, \n",
    "    d_ff=h.d_ff, \n",
    "    vocab_size=h.vocab_size, \n",
    "    dropout=h.dropout, \n",
    "    max_len=h.max_len\n",
    ").to('cuda')\n",
    "model.load_state_dict(torch.load('ckpt')['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 .parquet files are found..\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/dhhyun/data/test'\n",
    "data = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Diese Frage hat Gutachs BÃ¼rgermeister gestern klar beantwortet.',\n",
       " \"Yesterday, Gutacht's Mayor gave a clear answer to this question.\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer from file...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "tokenizer = load_tokenizer(h.tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 3003 / train: 2994\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set = get_and_split_dataset(data, tokenizer, h.valid_ratio, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12828,  3705,    29, 14715,  4178,  5698,  3724,  8003,    74,  6794,\n",
      "            3], device='cuda:0')\n",
      "torch.Size([13])\n",
      "torch.Size([13])\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0][0])\n",
    "print(train_set[0][1].shape)\n",
    "print(train_set[0][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "pred = model(train_set[i][0].unsqueeze(0), train_set[i][1].unsqueeze(0)).squeeze(0)\n",
    "ground_truth = train_set[i][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 15000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(pred, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.305244445800781"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5906, 5320,   15, 5272, 3639,   10,   86,   15, 5574, 4660,   68, 4660,\n",
      "        4660, 3644, 3780, 5272,   17,    3], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"These issue , question and ' s , citizens clear a clear clear to this question .\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ids = torch.argmax(pred, -1)\n",
    "print(pred_ids)\n",
    "tokenizer.decode(pred_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
